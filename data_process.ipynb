{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c67b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 11:44:25.150275: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#necessary imports\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob,os\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "# from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81b1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24703be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from each .wav file\n",
    "def extract_features(data, sample_rate):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4429c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate = rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sr = sampling_rate, n_steps = pitch_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02f1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotions in the dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  #'02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  #'07':'disgust',\n",
    "  #'08':'surprised'\n",
    "}\n",
    "\n",
    "#Emotions to observe\n",
    "#observed_emotions=['calm', 'happy', 'fearful', 'disgust', 'sad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f996d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions2={\n",
    "    'NEU': 'neutral',\n",
    "    'HAP': 'happy',\n",
    "    'SAD': 'sad',\n",
    "    'ANG': 'angry',\n",
    "    'FEA': 'fearful',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa4489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path, isTraining):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    #data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    data, sample_rate = librosa.load(path, duration=2, offset=0.6, sr=8025)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # Augmenting only training data and skipping augmentation for test data\n",
    "    if isTraining:\n",
    "        \n",
    "        # data with noise\n",
    "        noise_data = noise(data)\n",
    "        res2 = extract_features(noise_data, sample_rate)\n",
    "        result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "        # data with stretching \n",
    "        stretched_data = stretch(data)\n",
    "        res3 = extract_features(stretched_data, sample_rate)\n",
    "        result = np.vstack((result, res3)) # stacking vertically\n",
    "        \n",
    "        # data with pitch offset\n",
    "        data_pitch = pitch(data, sample_rate)\n",
    "        res4 = extract_features(data_pitch, sample_rate)\n",
    "        result = np.vstack((result, res4)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b0424",
   "metadata": {},
   "source": [
    "# New Data\n",
    "## Crema-D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f446730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry      1271\n",
      "sad        1271\n",
      "fearful    1271\n",
      "happy      1271\n",
      "neutral    1087\n",
      "Name: Emotions, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Creama = \"data2/\"\n",
    "creama_directory_list = os.listdir(Creama)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for file in glob.glob(f\"{Creama}*\"):\n",
    "    part = file.split('.')[0]\n",
    "    part = part.split('_')\n",
    "    if part[2] not in emotions2.keys():\n",
    "        continue\n",
    "    file_emotion.append(part[2])\n",
    "    file_path.append(file)\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion2_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files\n",
    "path2_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Creama_df = pd.concat([emotion2_df, path2_df], axis=1)\n",
    "\n",
    "# Mapping integers to corresponding emotions\n",
    "Creama_df = Creama_df.replace({'Emotions': emotions2})\n",
    "print(Creama_df[\"Emotions\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb984459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angry      192\n",
       "fearful    192\n",
       "sad        192\n",
       "happy      192\n",
       "neutral     96\n",
       "Name: Emotions, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframes\n",
    "Ravdess = \"data/\"\n",
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for folder in glob.glob(f\"{Ravdess}Actor_*\"):\n",
    "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(folder)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        # third part in each file represents the emotion associated to that file.\n",
    "        if part[2] not in emotions.keys():\n",
    "            continue\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(folder + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "\n",
    "# dataframe for path of files\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "# Mapping integers to corresponding emotions\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fearful'}, inplace=True)\n",
    "\n",
    "Ravdess_df['Emotions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56cc158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([Creama_df, Ravdess_df], axis=0)\n",
    "\n",
    "X = data[\"Path\"]\n",
    "Y = data[\"Emotions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1a1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "746e8032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sad        1129\n",
       " happy      1099\n",
       " fearful    1096\n",
       " angry      1071\n",
       " neutral     881\n",
       " Name: Emotions, dtype: int64,\n",
       " angry      392\n",
       " fearful    367\n",
       " happy      364\n",
       " sad        334\n",
       " neutral    302\n",
       " Name: Emotions, dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts(), Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aa2e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5276,)\n",
      "(5276,)\n",
      "(1759,)\n",
      "(1759,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8323543",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X, Y \u001b[39m=\u001b[39m [], []\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m path, emotion \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_train, Y_train):\n\u001b[0;32m----> 3\u001b[0m     feature \u001b[39m=\u001b[39m get_features(path, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m ele \u001b[39min\u001b[39;00m feature:\n\u001b[1;32m      5\u001b[0m         X\u001b[39m.\u001b[39mappend(ele)\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(path, isTraining)\u001b[0m\n\u001b[1;32m      4\u001b[0m data, sample_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mload(path, duration\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, offset\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m, sr\u001b[39m=\u001b[39m\u001b[39m8025\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# without augmentation\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m res1 \u001b[39m=\u001b[39m extract_features(data, sample_rate)\n\u001b[1;32m      8\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(res1)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Augmenting only training data and skipping augmentation for test data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(data, sample_rate)\u001b[0m\n\u001b[1;32m     19\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack((result, rms)) \u001b[39m# stacking horizontally\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# MelSpectogram\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m mel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(librosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49mmelspectrogram(y\u001b[39m=\u001b[39;49mdata, sr\u001b[39m=\u001b[39;49msample_rate)\u001b[39m.\u001b[39mT, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack((result, mel)) \u001b[39m# stacking horizontally\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/feature/spectral.py:2157\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m S, n_fft \u001b[39m=\u001b[39m _spectrogram(\n\u001b[1;32m   2145\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[1;32m   2146\u001b[0m     S\u001b[39m=\u001b[39mS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     pad_mode\u001b[39m=\u001b[39mpad_mode,\n\u001b[1;32m   2154\u001b[0m )\n\u001b[1;32m   2156\u001b[0m \u001b[39m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m-> 2157\u001b[0m mel_basis \u001b[39m=\u001b[39m filters\u001b[39m.\u001b[39;49mmel(sr\u001b[39m=\u001b[39;49msr, n_fft\u001b[39m=\u001b[39;49mn_fft, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2159\u001b[0m melspec: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39m...ft,mf->...mt\u001b[39m\u001b[39m\"\u001b[39m, S, mel_basis, optimize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2160\u001b[0m \u001b[39mreturn\u001b[39;00m melspec\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/filters.py:240\u001b[0m, in \u001b[0;36mmel\u001b[0;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m     upper \u001b[39m=\u001b[39m ramps[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m] \u001b[39m/\u001b[39m fdiff[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m    239\u001b[0m     \u001b[39m# .. then intersect them with each other and zero\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     weights[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39;49mminimum(lower, upper))\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(norm, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m norm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mslaney\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    244\u001b[0m         \u001b[39m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(X_train, Y_train):\n",
    "    feature = get_features(path, True)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        # appending emotion 4 times as we have applied 4 augmentation techniques on each audio file\n",
    "        Y.append(emotion)\n",
    "x_train = X\n",
    "y_train = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d3001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.786461</td>\n",
       "      <td>0.788402</td>\n",
       "      <td>0.502173</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.488599</td>\n",
       "      <td>0.458573</td>\n",
       "      <td>0.497425</td>\n",
       "      <td>0.589869</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106477</td>\n",
       "      <td>0.037218</td>\n",
       "      <td>0.030323</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.197499</td>\n",
       "      <td>0.794354</td>\n",
       "      <td>0.684380</td>\n",
       "      <td>0.456011</td>\n",
       "      <td>0.470637</td>\n",
       "      <td>0.497837</td>\n",
       "      <td>0.486151</td>\n",
       "      <td>0.527306</td>\n",
       "      <td>0.641404</td>\n",
       "      <td>0.627995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105259</td>\n",
       "      <td>0.037137</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155408</td>\n",
       "      <td>0.906215</td>\n",
       "      <td>0.619200</td>\n",
       "      <td>0.418835</td>\n",
       "      <td>0.486907</td>\n",
       "      <td>0.462776</td>\n",
       "      <td>0.463361</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.655547</td>\n",
       "      <td>0.588477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066172</td>\n",
       "      <td>0.022858</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.012879</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161833</td>\n",
       "      <td>0.527145</td>\n",
       "      <td>0.869874</td>\n",
       "      <td>0.795607</td>\n",
       "      <td>0.476046</td>\n",
       "      <td>0.447058</td>\n",
       "      <td>0.478203</td>\n",
       "      <td>0.410140</td>\n",
       "      <td>0.459286</td>\n",
       "      <td>0.580427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083353</td>\n",
       "      <td>0.028837</td>\n",
       "      <td>0.070650</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123682</td>\n",
       "      <td>0.609155</td>\n",
       "      <td>0.439890</td>\n",
       "      <td>0.468290</td>\n",
       "      <td>0.535586</td>\n",
       "      <td>0.620048</td>\n",
       "      <td>0.572363</td>\n",
       "      <td>0.580419</td>\n",
       "      <td>0.533955</td>\n",
       "      <td>0.571267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.091899</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.132812  0.786461  0.788402  0.502173  0.456299  0.488599  0.458573   \n",
       "1  0.197499  0.794354  0.684380  0.456011  0.470637  0.497837  0.486151   \n",
       "2  0.155408  0.906215  0.619200  0.418835  0.486907  0.462776  0.463361   \n",
       "3  0.161833  0.527145  0.869874  0.795607  0.476046  0.447058  0.478203   \n",
       "4  0.123682  0.609155  0.439890  0.468290  0.535586  0.620048  0.572363   \n",
       "\n",
       "          7         8         9  ...       153       154       155       156  \\\n",
       "0  0.497425  0.589869  0.639345  ...  0.106477  0.037218  0.030323  0.022959   \n",
       "1  0.527306  0.641404  0.627995  ...  0.105259  0.037137  0.030578  0.023704   \n",
       "2  0.517800  0.655547  0.588477  ...  0.066172  0.022858  0.017371  0.012629   \n",
       "3  0.410140  0.459286  0.580427  ...  0.083353  0.028837  0.070650  0.033715   \n",
       "4  0.580419  0.533955  0.571267  ...  0.033259  0.025641  0.091899  0.020896   \n",
       "\n",
       "        157       158       159       160       161  labels  \n",
       "0  0.034632  0.018931  0.007288  0.001811  0.000043   angry  \n",
       "1  0.035130  0.019389  0.007926  0.002445  0.000779   angry  \n",
       "2  0.020867  0.012879  0.005110  0.001129  0.000024   angry  \n",
       "3  0.023035  0.016411  0.013157  0.004276  0.000025   angry  \n",
       "4  0.011710  0.024206  0.016897  0.003146  0.000130   angry  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving features in a csv file to avoid redundant feature extraction\n",
    "Features = pd.DataFrame(x_train)\n",
    "Features['labels'] = y_train\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be64a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'angry' 'angry' ... 'fearful' 'fearful' 'fearful']\n"
     ]
    }
   ],
   "source": [
    "x_train = Features.iloc[: ,:-1].values\n",
    "y_train = Features['labels'].values\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cee47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encoder = sklearn.preprocessing.OneHotEncoder()\n",
    "y_train = encoder.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ad66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1759, 162)\n",
      "(1759,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(X_test, Y_test):\n",
    "    feature = get_features(path, False)   \n",
    "    X.append(feature)\n",
    "    Y.append(emotion)\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "x_test = np.array(X)\n",
    "y_test = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4003      happy\n",
       "474         sad\n",
       "3927        sad\n",
       "4694    fearful\n",
       "1237    fearful\n",
       "Name: Emotions, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3a53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4003                 data2/1048_IEO_HAP_MD.wav\n",
       "474     data/Actor_09/03-01-04-02-01-02-09.wav\n",
       "3927                 data2/1038_TSI_SAD_XX.wav\n",
       "4694                 data2/1024_TIE_FEA_XX.wav\n",
       "1237                 data2/1044_TSI_FEA_XX.wav\n",
       "Name: Path, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb211d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = sklearn.preprocessing.OneHotEncoder()\n",
    "y_test = encoder.fit_transform(np.array(y_test).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21104, 162), (21104, 6), (1759, 162), (1759, 6))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4019329164297897\n"
     ]
    }
   ],
   "source": [
    "model1=MLPClassifier(alpha=0.01, batch_size=64, epsilon=1e-08, hidden_layer_sizes=(500,), learning_rate='adaptive', max_iter=500)\n",
    "model1.fit(x_train,y_train)\n",
    "score = model1.score(x_test, y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1164fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21104, 162, 1), (21104, 6), (1759, 162, 1), (1759, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping train and test data for new model\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
